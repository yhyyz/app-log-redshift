# for emr ec2
aws_region = us-east-1
s3_endpoint = s3.us-east-1.amazonaws.com
checkpoint_location = s3://panchao-data/spark-redshift-realtime-log-ec2/checkpoint-test/
checkpoint_interval = 30 seconds
kafka_broker = b-1.commonmskpanchao.wp46nn.c9.kafka.us-east-1.amazonaws.com:9092
topic = app_log_realtime
startingOffsets = latest
thread_max_workers = 30
disable_msg = true
max_offsets_per_trigger = 1000000
consumer_group = realtime-log-redshift-ec2-g1
# write s3 temp file format, CSV,CSV GZIP,JSON, JSON GZIP. default CSV
tempformat = JSON
redshift_secret_id =
redshift_host = stress-4x.cgpqploshmmo.us-east-1.redshift.amazonaws.com
redshift_port = 5439
redshift_username = ssa
redshift_password = Ssa123456
redshift_database = dev
redshift_schema = cdc_data_04
redshift_tmpdir = s3://panchao-data/spark-redshift-log-realtime-ec2/tmpdir/
redshift_iam_role = arn:aws:iam::946277762357:role/admin-role-panchao

metadata_host = ssa-panchao-db.cojrbrhcpw9s.us-east-1.rds.amazonaws.com
metadata_port = 3306
metadata_username = ssa
metadata_password = Ssa123456
metadata_database = app_log
metadata_event_type = 1
target_table = "realtime_events"
